{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee26e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 1/29\n",
      "Processing frame 2/29\n",
      "Processing frame 3/29\n",
      "Processing frame 4/29\n",
      "Processing frame 5/29\n",
      "Processing frame 6/29\n",
      "Processing frame 7/29\n",
      "Processing frame 8/29\n",
      "Processing frame 9/29\n",
      "Processing frame 10/29\n",
      "Processing frame 11/29\n",
      "Processing frame 12/29\n",
      "Processing frame 13/29\n",
      "Processing frame 14/29\n",
      "Processing frame 15/29\n",
      "Processing frame 16/29\n",
      "Processing frame 17/29\n",
      "Processing frame 18/29\n",
      "Processing frame 19/29\n",
      "Processing frame 20/29\n",
      "Processing frame 21/29\n",
      "Processing frame 22/29\n",
      "Processing frame 23/29\n",
      "Processing frame 24/29\n",
      "Processing frame 25/29\n",
      "Processing frame 26/29\n",
      "Processing frame 27/29\n",
      "Processing frame 28/29\n",
      "Processing frame 29/29\n",
      "Video processing completed\n",
      "Output video saved to: ../output_gaze/video12.mp4\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from face_detection import RetinaFace\n",
    "\n",
    "from l2cs import select_device, draw_gaze, getArch, Pipeline, render\n",
    "\n",
    "CWD = pathlib.Path.cwd()\n",
    "\n",
    "# 设置参数\n",
    "video_path = '../test_gaze/video_12.mp4'  # 修改为你的视频路径\n",
    "output_path = '../output_gaze/video_12.mp4'\n",
    "device = 'mps'  # 改为 'gpu:0' 如果有 GPU\n",
    "arch = 'ResNet121'\n",
    "\n",
    "cudnn.enabled = True\n",
    "\n",
    "gaze_pipeline = Pipeline(\n",
    "    weights=CWD / 'models' / 'L2CSNet_gaze360.pkl',\n",
    "    arch='ResNet50',\n",
    "    device = select_device(device, batch_size=1)\n",
    ")\n",
    " \n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video file is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(f\"Cannot open video file: {video_path}\")\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Define video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "if not out.isOpened():\n",
    "    raise IOError(f\"Cannot create video writer for: {output_path}\")\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    while True:\n",
    "\n",
    "        # Get frame\n",
    "        success, frame = cap.read()    \n",
    "        start_fps = time.time()  \n",
    "\n",
    "        if not success:\n",
    "            print(\"Video processing completed\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "\n",
    "        # Process frame\n",
    "        results = gaze_pipeline.step(frame)\n",
    "\n",
    "        # Visualize output\n",
    "        frame = render(frame, results)\n",
    "       \n",
    "        myFPS = 1.0 / (time.time() - start_fps)\n",
    "        cv2.putText(frame, 'FPS: {:.1f}'.format(myFPS), (10, 20),cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Write frame to output video\n",
    "        out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Output video saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vibe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
